{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOlULJMNGSkOQ1a4edvrS6B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Andrespinedap/AlgoritmoNoSupervisadoM/blob/main/algoritmonosupervisado.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sección nueva"
      ],
      "metadata": {
        "id": "clYNcRakEU6v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar librerías necesarias\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# 1. Carga de datos\n",
        "# Para este ejemplo, utilizaremos el dataset de iris de Scikit-Learn\n",
        "from sklearn.datasets import load_iris\n",
        "data = load_iris()\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "\n",
        "# 2. Exploración básica de los datos\n",
        "print(\"Primeras filas del conjunto de datos:\")\n",
        "print(df.head())\n",
        "print(\"\\nDescripción del conjunto de datos:\")\n",
        "print(df.describe())\n",
        "\n",
        "# 3. Escalado de los datos\n",
        "# Escalar los datos es importante para algoritmos basados en distancia como K-Means\n",
        "scaler = StandardScaler()\n",
        "scaled_data = scaler.fit_transform(df)\n",
        "\n",
        "# 4. Reducción de dimensionalidad con PCA (para visualización)\n",
        "# Reducimos a 2 componentes principales para poder visualizar los clústeres\n",
        "pca = PCA(n_components=2)\n",
        "pca_data = pca.fit_transform(scaled_data)\n",
        "pca_df = pd.DataFrame(pca_data, columns=['PCA1', 'PCA2'])\n",
        "\n",
        "# 5. Implementación del algoritmo K-Means\n",
        "# Elegimos 3 clústeres (sabemos que el dataset de iris tiene 3 clases naturales)\n",
        "kmeans = KMeans(n_clusters=3, random_state=42)\n",
        "pca_df['Cluster'] = kmeans.fit_predict(scaled_data)\n",
        "\n",
        "# 6. Visualización de los resultados\n",
        "# Visualizamos los clústeres resultantes en las dos primeras componentes principales\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(x='PCA1', y='PCA2', hue='Cluster', data=pca_df, palette='viridis')\n",
        "plt.title('Visualización de Clústeres usando K-Means con reducción PCA')\n",
        "plt.xlabel('Componente Principal 1')\n",
        "plt.ylabel('Componente Principal 2')\n",
        "plt.legend(title='Clúster')\n",
        "plt.show()\n",
        "\n",
        "# 7. Interpretación de resultados\n",
        "# Los puntos de colores diferentes representan distintos clústeres identificados por K-Means.\n",
        "# Podemos observar cómo el algoritmo ha agrupado los datos en tres grupos, representados con diferentes colores.\n",
        "\n",
        "# Nota sobre el uso del código:\n",
        "# Este análisis implementa el algoritmo de clustering K-Means y muestra los resultados mediante reducción de dimensionalidad con PCA.\n",
        "# La interpretación visual sugiere cómo el algoritmo ha segmentado los datos en diferentes clústeres.\n"
      ],
      "metadata": {
        "id": "FT0itE8NIm00"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}